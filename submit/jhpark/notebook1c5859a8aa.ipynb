{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"},{"sourceId":7584174,"sourceType":"datasetVersion","datasetId":4414761},{"sourceId":8157677,"sourceType":"datasetVersion","datasetId":4825862},{"sourceId":33442,"sourceType":"modelInstanceVersion","modelInstanceId":27615},{"sourceId":33452,"sourceType":"modelInstanceVersion","modelInstanceId":27615},{"sourceId":33454,"sourceType":"modelInstanceVersion","modelInstanceId":27615}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install tensorflow keras --upgrade --no-index --find-links /kaggle/input/package","metadata":{"execution":{"iopub.status.busy":"2024-04-18T16:14:57.639523Z","iopub.execute_input":"2024-04-18T16:14:57.639932Z","iopub.status.idle":"2024-04-18T16:15:07.652639Z","shell.execute_reply.started":"2024-04-18T16:14:57.639908Z","shell.execute_reply":"2024-04-18T16:15:07.651537Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/package\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as tf_keras\n\ntf.__version__","metadata":{"execution":{"iopub.status.busy":"2024-04-18T16:16:08.656666Z","iopub.execute_input":"2024-04-18T16:16:08.657117Z","iopub.status.idle":"2024-04-18T16:16:08.665761Z","shell.execute_reply.started":"2024-04-18T16:16:08.657081Z","shell.execute_reply":"2024-04-18T16:16:08.664735Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"'2.15.0'"},"metadata":{}}]},{"cell_type":"code","source":"from typing import Dict, Optional\n\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.python.framework.dtypes import DType\n\nclass DeepCrossNetwork(tf_keras.Model):\n    def __init__(self,\n                 transformations_by_feature: Dict[str, object],\n                 **kwargs):\n        super(DeepCrossNetwork, self).__init__(**kwargs)\n        self.transformations_by_feature = transformations_by_feature\n        self._build_layers()\n\n\n    def _parse_into_layer(self, transformation: Dict[str, object]):\n        type = transformation['type']\n        feature_props = transformation['properties']\n\n        if type == 'numerical_embedding':\n            return tf_keras.layers.Embedding(feature_props['vocab_size'], feature_props['embedding_size'])\n        elif type == 'onehot':\n            return tf_keras.layers.StringLookup(vocabulary=feature_props['vocab'] + ['NA'], output_mode='one_hot')\n        elif type == 'binning':\n            return tf_keras.layers.Discretization(bin_boundaries=feature_props['boundaries'])\n        elif type == 'standardization':\n            tf_keras.layers.Normalization(mean=feature_props['mean'], variance=feature_props['stddev'])\n        else:\n            return tf_keras.layers.Identity()\n\n    def _build_layers(self):\n        input_by_feature_name, transformed_by_feature_name = {}, {}\n        for feature, transformation in self.transformations_by_feature.items():\n            transformation = self._parse_into_layer(transformation)\n            dtype = self._get_dtype_by_transformation(transformation)\n            inputs_placeholder = tf_keras.Input((1, ),\n                                                dtype=dtype,\n                                                name=feature)\n            transformed = tf.cast(transformation(inputs_placeholder), tf.float32)\n\n            input_by_feature_name[feature] = inputs_placeholder\n            transformed_by_feature_name[feature] = transformed\n\n        concatenated_input = tf_keras.layers.Concatenate(axis=-1)(list(transformed_by_feature_name.values()))\n        cross_layer_output = self._build_cross_layers(concatenated_input)\n        logits = self._build_dense_layers(inputs=cross_layer_output)\n\n        self.model = Model(input_by_feature_name, logits)\n\n    def _get_dtype_by_transformation(self, transformation: tf_keras.layers.Layer) -> DType:\n        if isinstance(transformation, tf_keras.layers.StringLookup):\n            return tf.string\n        return tf.float32\n\n    def _build_cross_layers(self, x0):\n        # TODO: Please add parameters\n        x1 = self._cross(x0, x0)\n        x2 = self._cross(x0, x1)\n\n        return x2\n\n\n    def _cross(self,\n               x0,\n               x1,\n               use_bias: bool = True,\n               activation: tf_keras.layers.Activation = None,\n               kernel_initializer: tf_keras.initializers.Initializer = tf_keras.initializers.truncated_normal,\n               bias_initializer: tf_keras.initializers.Initializer = tf_keras.initializers.zeros,\n               kernel_regularizer: Optional[tf_keras.regularizers.Regularizer] = None,\n               bias_regularizer: Optional[tf_keras.regularizers.Regularizer] = None) -> tf.Tensor:\n        layer = tf_keras.layers.Dense(\n            x0.shape[-1],\n            kernel_initializer=kernel_initializer,\n            bias_initializer=bias_initializer,\n            kernel_regularizer=kernel_regularizer,\n            bias_regularizer=bias_regularizer,\n            use_bias=use_bias,\n            dtype=x0.dtype,\n            activation=activation,\n        )\n\n        result = layer(x1)\n        result = tf.cast(result, x0.dtype)\n\n        return x0 * result + result\n\n\n    def _build_dense_layers(self, inputs):\n        # TODO: Please add parameters\n        layer1 = Dense(50, activation=tf_keras.activations.relu)\n        layer2 = Dense(30, activation=tf_keras.activations.relu)\n\n        output = layer2(layer1(inputs))\n        logits = Dense(units=1, activation=tf_keras.activations.sigmoid)(output)\n\n        return logits\n\n    def call(self, inputs):\n        return self.model(inputs)\n\n    def get_config(self):\n        return {\"transformations_by_feature\": self.transformations_by_feature}\n\n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\n\nDeepCrossNetwork.__module__ = 'model.dcn'","metadata":{"execution":{"iopub.status.busy":"2024-04-18T16:16:12.807060Z","iopub.execute_input":"2024-04-18T16:16:12.807436Z","iopub.status.idle":"2024-04-18T16:16:12.829275Z","shell.execute_reply.started":"2024-04-18T16:16:12.807411Z","shell.execute_reply":"2024-04-18T16:16:12.827788Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nDATA_PATH = \"/kaggle/input/home-credit-credit-risk-model-stability/\"\nTEST_DATA_PATH = \"/tmp/test.parquet\"\nSEED = 617\n\nimport os\nos.environ['TF_USE_LEGACY_KERAS'] = '1'\nimport pandas as pd\nfrom pathlib import Path\nfrom argparse import Namespace\nfrom dataclasses import dataclass\nfrom pyarrow.parquet import ParquetFile\n\nPOSTFIXES = {\n    \"P\": \"Transform DPD (Days Past Due)\",\n    \"M\": \"Masking Categories\",\n    \"A\": \"Transform Amount\",\n    \"D\": \"Transform Date\",\n    \"T\": \"Unspecified Transform\",\n    \"L\": \"Unspecified Transform\",\n}\n\n\nclass RawFile:\n    def __init__(self, file_name: str = \"\") -> None:\n        self.file_name = str(file_name)\n\n        if isinstance(self.file_name, str) and self.file_name:\n            (\n                self._type,\n                self._name,\n                self._depth,\n                self._index,\n                self._file_format\n            ) = self._parse_file_name()\n        else:\n            raise ValueError(f\"file_name should be a non-empty string. Not {file_name}.\")\n\n    def __repr__(self) -> str:\n        return f\"{self.file_name}\"\n\n    def __str__(self) -> str:\n        return self.file_name\n\n    def __lt__(self, other) -> bool:\n        return self.file_name < other.file_name\n\n    @property\n    def type(self) -> str:\n        return self._type\n\n    @property\n    def depth(self) -> str:\n        return self._depth\n\n    @property\n    def index(self) -> str:\n        return self._index\n\n    @property\n    def format(self) -> str:\n        return self._file_format\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @property\n    def fullname(self) -> str:\n        return self.file_name.rsplit(\".\", 1)[0]\n\n    def _parse_file_name(self) -> tuple[str, str, str, str]:\n        fullname = self.fullname\n        file_format = self.file_name.rsplit(\".\", 1)[1]\n\n        names = fullname.split(\"_\")\n        if names[-2].isdigit():\n            return names[0], \"_\".join(names[1:-2]), names[-2], names[-1], file_format\n        elif names[-1].isdigit():\n            return names[0], \"_\".join(names[1:-1]), names[-1], \"\", file_format\n        else:\n            return names[0], \"_\".join(names[1:]), \"\", \"\", file_format\n\n    def get_path(self, data_dir: Path = None) -> Path:\n        if data_dir is None:\n            data_dir = DATA_PATH\n        return Path(data_dir) / f\"{self.format}_files\" / self.type / self.file_name\n\n    def startswith(self, keyword: str) -> bool:\n        return self.file_name.startswith(keyword)\n\n\n@dataclass\nclass ColInfo:\n    name: str\n\n    def __repr__(self) -> str:\n        return self.name\n\n    def __str__(self) -> str:\n        return self.name\n\n    @property\n    def desc(self) -> str:\n        return self.describe()\n\n    def describe(\n            self,\n            description_file: str = \"feature_definitions.csv\"\n    ) -> str:\n        description_df = pd.read_csv(DATA_PATH / description_file, usecols=[\"Variable\", \"Description\"])\n\n        if self.name in description_df[\"Variable\"].values:\n            result_description = (\n                description_df.loc[\n                    description_df[\"Variable\"] == self.name, \"Description\"\n                ].values[0])\n        else:\n            result_description = self.name\n\n        if self.name[-1] in POSTFIXES:\n            return f\"{self.name}: {result_description} ({POSTFIXES[self.name[-1]]})\"\n        else:\n            return f\"{self.name}: {result_description}\"\n\n\nclass RawReader:\n    def __init__(self, format_: str = \"parquet\") -> None:\n        self.format = format_\n\n        if format_ == \"parquet\":\n            self.reader = pd.read_parquet\n            self.column_getter = self._get_parquet_columns\n        elif format_ == \"csv\":\n            self.reader = pd.read_csv\n            self.column_getter = self._get_csv_columns\n        else:\n            raise ValueError(f\"format_ should be either 'parquet' or 'csv'. Not {format_}.\")\n\n    def read(self, file_path: Path) -> pd.DataFrame:\n        return self.reader(file_path)\n\n    def columns(self, file_path: Path) -> list[ColInfo]:\n        return [ColInfo(c) for c in self.column_getter(file_path)]\n\n    def _get_csv_columns(self, file_path: Path) -> list[ColInfo]:\n        return [c for c in self.reader(file_path, nrows=0).columns]\n\n    def _get_parquet_columns(self, file_path: Path) -> list[ColInfo]:\n        return [c for c in ParquetFile(file_path).columns]\n\n    def __call__(self, file_path) -> pd.DataFrame:\n        return self.read(file_path)\n\n\nclass RawInfo:\n    VALID_TYPES = [\"\", \"train\", \"test\"]\n    VALID_DEPTHS = [\"\", \"0\", \"1\", \"2\"]\n\n    def __init__(self, config: dict = None) -> None:\n        self.config = config\n        if self.config is None:\n            self.config = Namespace(**{\n                \"data_path\": DATA_PATH,\n                \"raw_format\": \"parquet\",\n            })\n\n        self.format = self.config.raw_format\n        self.data_dir_path = Path(self.config.data_path)\n        self.file_dir_path = self.data_dir_path / f\"{self.format}_files\"\n\n        if not self.file_dir_path.exists():\n            raise FileNotFoundError(f\"{self.file_dir_path} does not exist.\")\n\n        self.reader = RawReader(self.format)\n\n    def show_files(self, type_: str = \"train\") -> list[RawFile]:\n        return sorted([RawFile(f) for f in os.listdir(self.file_dir_path / type_)])\n\n    def get_files(self, filename: str, *, depth: int = None, type_: str = \"train\") -> list[RawFile]:\n        if depth is None:\n            return sorted([\n                f for f in self.show_files(type_) if f.name == filename])\n        else:\n            return sorted([\n                f for f in self.show_files(type_)\n                if f.name == filename and f.depth == str(depth)])\n\n    def get_depths_by_name(self, file_name: str, type_: str = \"train\") -> list[int]:\n        return sorted(list(set([int(f.depth) for f in self.get_files(file_name, type_=type_)])))\n\n    def get_files_by_depth(self, depth: int, type_: str = \"train\") -> list[RawFile]:\n        return [f for f in self.show_files(type_) if f.depth == str(depth)]\n\n    def read_raw(\n            self,\n            file_name: str,\n            *,\n            depth: int = None,\n            type_: str = \"train\",\n    ) -> pd.DataFrame:\n        raw_files = self.get_files(file_name, depth=depth, type_=type_)\n\n        if len(raw_files) > 0:\n            raw_df = pd.concat([self.reader(rf.get_path(self.data_dir_path)) for rf in raw_files])\n        else:\n            raise FileNotFoundError(f\"{file_name} (depth: {depth}) does not exist in {type_} files.\")\n\n        return raw_df\n\n\ndef prepare_base_data(conf: Namespace = None, type_: str = \"train\"):\n    print(\"prepare_base_data ...\")\n    infos = RawInfo(conf)\n    base_df = infos.read_raw(\"base\", type_=type_)\n    static_df = infos.read_raw(\"static\", depth=0, type_=type_)\n    static_cb_df = infos.read_raw(\"static_cb\", depth=0, type_=type_)\n\n    joined_df = pd.merge(base_df, static_df, on=\"case_id\", how=\"left\", suffixes=(\"_base\", \"_static\"))\n    joined_df = pd.merge(joined_df, static_cb_df, on=\"case_id\", how=\"left\", suffixes=(\"\", \"_static_cb\"))\n    \n    return joined_df\n\n\ndef devval(df):\n    conditions = [\n        df[\"MONTH\"].between(201909, 202008),\n        df[\"MONTH\"].between(201901, 201908)\n    ]\n    choices = [0, 1]\n    df['devval'] = np.select(conditions, choices, default=2)\n\ntrain_base_static = prepare_base_data()\ntest_base_static = prepare_base_data(type_=\"test\")\n\ndevval(train_base_static)\n\n# only use test path\n# dev = train_base_static[train_base_static[\"devval\"] == 0].drop(\"devval\", axis=1)\n# val = train_base_static[train_base_static[\"devval\"] == 1].drop(\"devval\", axis=1)\ntest = train_base_static[train_base_static[\"devval\"] == 2].drop(\"devval\", axis=1)\n\ntest.to_parquet(TEST_DATA_PATH)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T16:16:14.249275Z","iopub.execute_input":"2024-04-18T16:16:14.249678Z","iopub.status.idle":"2024-04-18T16:16:39.133443Z","shell.execute_reply.started":"2024-04-18T16:16:14.249652Z","shell.execute_reply":"2024-04-18T16:16:39.131154Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"prepare_base_data ...\nprepare_base_data ...\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport kagglehub\nimport tensorflow.keras as tf_keras\nimport tensorflow_io as tfio\n\npath = kagglehub.model_download(\"josh9191/homecredit/tensorFlow2/dcn\")\nmodel_path = \"/kaggle/input/homecredit/tensorflow2/dcn/5\"\n\nkeras_model = tf_keras.models.load_model(model_path)\n\n# df = pd.read_parquet(TEST_DATA_PATH, , engine='pyarrow')\ndf = pd.read_parquet(TEST_DATA_PATH, columns=['case_id', 'annuity_780A', 'credamount_770A', 'credtype_322L', 'disbursedcredamount_1113A'], engine='pyarrow')\ncase_id = df['case_id'].to_numpy()\ndf.drop(columns=['case_id'], inplace=True)\n\nfloat64_cols = list(df.select_dtypes(include='float64'))\ndf[float64_cols] = df[float64_cols].astype('float32')\n\narray_dict = {k: v.to_numpy() for k, v in df.to_dict(\"series\").items()}\npreds = keras_model.predict(array_dict).reshape((-1,))\n\nsubmission = pd.DataFrame({\n    \"case_id\": case_id,\n    \"score\": preds\n}).set_index('case_id')\nsubmission.to_csv(\"./submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T16:16:39.137890Z","iopub.execute_input":"2024-04-18T16:16:39.138539Z","iopub.status.idle":"2024-04-18T16:16:46.790034Z","shell.execute_reply.started":"2024-04-18T16:16:39.138474Z","shell.execute_reply":"2024-04-18T16:16:46.788844Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stderr","text":"Attaching model 'josh9191/homecredit/tensorFlow2/dcn' to your Kaggle notebook...\n","output_type":"stream"},{"name":"stdout","text":"2204/2204 [==============================] - 5s 2ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}